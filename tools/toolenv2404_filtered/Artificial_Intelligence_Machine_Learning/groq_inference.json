{
    "product_id": "api_0ff2eca5-f8b3-405b-bf2f-1374a92e3e82",
    "tool_description": "Get the fastest inferencing (600-800 words/sec*) from all Groq models at even cheaper rates than the official site",
    "home_url": "https://rapidapi.com/sreesocialmedialtd/api/groq-inference1/",
    "name": "Groq-Inference",
    "title": "Groq-Inference",
    "pricing": "FREEMIUM",
    "tool_name": "Groq-Inference",
    "score": {
        "avgServiceLevel": 100,
        "avgLatency": 9112,
        "avgSuccessRate": 100,
        "popularityScore": 6.3,
        "__typename": "Score"
    },
    "host": "groq-inference1.p.rapidapi.com",
    "api_list": [
        {
            "name": "/chat",
            "url": "https://groq-inference1.p.rapidapi.com/chat",
            "description": "The /chat route of our API enables users to interact with a large language model by sending queries and receiving responses. The route processes user queries, sends them to the LLM, and returns the generated responses with high speed and accuracy. Our API delivers efficient and reliable results, making it an ideal choice for users seeking to leverage the capabilities of an LLM.",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "query",
                    "type": "STRING",
                    "description": "",
                    "default": "What is the capital of India"
                }
            ],
            "optional_parameters": [
                {
                    "name": "assistant",
                    "type": "STRING",
                    "description": "",
                    "default": "[Assistant Prompt]"
                },
                {
                    "name": "system",
                    "type": "STRING",
                    "description": "",
                    "default": "[System Prompt]"
                },
                {
                    "name": "temperature",
                    "type": "STRING",
                    "description": "",
                    "default": "0.7"
                },
                {
                    "name": "max_tokens",
                    "type": "STRING",
                    "description": "",
                    "default": "300"
                },
                {
                    "name": "model",
                    "type": "STRING",
                    "description": "",
                    "default": "mistral (supports interaction with all language models from Groq, including Gemma and Llama. These models can be specified as parameters using only their base names and are regularly updated)"
                }
            ],
            "code": "import requests\n\nurl = \"https://groq-inference1.p.rapidapi.com/chat\"\nquerystring = {\"assistant\": \"[Assistant Prompt]\", \"system\": \"[System Prompt]\", \"temperature\": \"0.7\", \"max_tokens\": \"300\", \"query\": \"What is the capital of India\", \"model\": \"mistral (supports interaction with all language models from Groq, including Gemma and Llama. These models can be specified as parameters using only their base names and are regularly updated)\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"groq-inference1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://groq-inference1.p.rapidapi.com/chat\"\nquerystring = {\"assistant\": \"[Assistant Prompt]\", \"system\": \"[System Prompt]\", \"temperature\": \"0.7\", \"max_tokens\": \"300\", \"query\": \"What is the capital of India\", \"model\": \"mistral (supports interaction with all language models from Groq, including Gemma and Llama. These models can be specified as parameters using only their base names and are regularly updated)\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"groq-inference1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 200,
            "schema": {}
        }
    ]
}