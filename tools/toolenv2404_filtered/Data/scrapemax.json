{
    "product_id": "api_ccb02af4-56b0-49fe-bbe7-78cda7b30c24",
    "tool_description": "ScrapeMax offers web scraping, web crawling with four endpoints: basic proxy scraping for standard requests, take screenshots of websites, headless browser scraping with proxy support for secure sites, and an endpoint for efficient image scraping using a headless browser and premium proxy. Ideal for data extraction with reliability and speed.\n\nFor any inquiries, requests, or assistance you may need, please don't hesitate to contact us at info@scrapemax.com. We're here to help!",
    "home_url": "https://rapidapi.com/scrapemax-scrapemax-default/api/scrapemax1/",
    "name": "Scrapemax",
    "title": "Scrapemax",
    "pricing": "FREEMIUM",
    "tool_name": "Scrapemax",
    "score": {
        "avgServiceLevel": 97,
        "avgLatency": 7951,
        "avgSuccessRate": 97,
        "popularityScore": 8.8,
        "__typename": "Score"
    },
    "host": "scrapemax1.p.rapidapi.com",
    "api_list": [
        {
            "name": "Take a screenshot",
            "url": "https://scrapemax1.p.rapidapi.com/screenshot",
            "description": "Take a website screenshot programmatically. Full page or only viewport.",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "target_url",
                    "type": "STRING",
                    "description": "",
                    "default": ""
                }
            ],
            "optional_parameters": [
                {
                    "name": "full_page",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                },
                {
                    "name": "proxy",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                },
                {
                    "name": "base64_encode",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                }
            ],
            "code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/screenshot\"\nquerystring = {\"full_page\": \"\", \"proxy\": \"\", \"target_url\": \"\", \"base64_encode\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/screenshot\"\nquerystring = {\"full_page\": \"\", \"proxy\": \"\", \"target_url\": \"\", \"base64_encode\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 200,
            "schema": {}
        },
        {
            "name": "Scrape image",
            "url": "https://scrapemax1.p.rapidapi.com/scrape-image",
            "description": "Special for image scraping with a real browser.",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "target_url",
                    "type": "STRING",
                    "description": "",
                    "default": ""
                }
            ],
            "optional_parameters": [
                {
                    "name": "download",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                },
                {
                    "name": "proxy",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                },
                {
                    "name": "base64_encode",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                }
            ],
            "code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/scrape-image\"\nquerystring = {\"download\": \"\", \"proxy\": \"\", \"base64_encode\": \"\", \"target_url\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/scrape-image\"\nquerystring = {\"download\": \"\", \"proxy\": \"\", \"base64_encode\": \"\", \"target_url\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 200,
            "schema": {}
        },
        {
            "name": "Scrape with browser",
            "url": "https://scrapemax1.p.rapidapi.com/scrape-js",
            "description": "Scrape with a JS enabled real browser.",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "target_url",
                    "type": "STRING",
                    "description": "",
                    "default": ""
                }
            ],
            "optional_parameters": [
                {
                    "name": "proxy",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                },
                {
                    "name": "base64_encode",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                }
            ],
            "code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/scrape-js\"\nquerystring = {\"proxy\": \"\", \"base64_encode\": \"\", \"target_url\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/scrape-js\"\nquerystring = {\"proxy\": \"\", \"base64_encode\": \"\", \"target_url\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 200,
            "schema": {}
        },
        {
            "name": "Scrape",
            "url": "https://scrapemax1.p.rapidapi.com/scrape",
            "description": "Scrape via GET method.",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "target_url",
                    "type": "STRING",
                    "description": "",
                    "default": ""
                }
            ],
            "optional_parameters": [
                {
                    "name": "proxy",
                    "type": "ENUM",
                    "description": "",
                    "default": ""
                },
                {
                    "name": "base64_encode",
                    "type": "ENUM",
                    "description": "Applies base64 encoding to response of target",
                    "default": ""
                }
            ],
            "code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/scrape\"\nquerystring = {\"target_url\": \"\", \"proxy\": \"\", \"base64_encode\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://scrapemax1.p.rapidapi.com/scrape\"\nquerystring = {\"target_url\": \"\", \"proxy\": \"\", \"base64_encode\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"scrapemax1.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 200,
            "schema": {}
        }
    ]
}