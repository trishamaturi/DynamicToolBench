{
    "product_id": "5613cc1ce4b07ae71ee3a97c",
    "tool_description": "This crawler will try to get any data possible from a given url, like title, description and images associated.",
    "home_url": "https://rapidapi.com/RicardoDMelo/api/webdata-crawler/",
    "name": "WebData Crawler",
    "title": "WebData Crawler",
    "pricing": "FREEMIUM",
    "tool_name": "WebData Crawler",
    "score": null,
    "host": "webdata-crawler.p.rapidapi.com",
    "api_list": [
        {
            "name": "Get WebData",
            "url": "https://webdata-crawler.p.rapidapi.com/webdata?url=https://github.com/&imgarr={imgarr}&generic={generic}",
            "description": "This service gets a json object with data from the url you provided.",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "url",
                    "type": "STRING",
                    "description": "Url you want to crawl. No \"hashtags\" (#) on the url. Only urls that return html.",
                    "default": "https://github.com/"
                }
            ],
            "optional_parameters": [
                {
                    "name": "generic",
                    "type": "BOOLEAN",
                    "description": "Default is FALSE. \"true\" will try to get a single generic image from the url if not explicitly provided at the html, ie. first image on website. Using imgarr parameter ignore this feature.",
                    "default": ""
                },
                {
                    "name": "imgarr",
                    "type": "BOOLEAN",
                    "description": "Default is FALSE. \"false\" for getting a single image from the url, \"true\" for getting all images in html.",
                    "default": ""
                }
            ],
            "code": "import requests\n\nurl = \"https://webdata-crawler.p.rapidapi.com/webdata?url=https://github.com/&imgarr={imgarr}&generic={generic}\"\nquerystring = {\"generic\": \"\", \"imgarr\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"webdata-crawler.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://webdata-crawler.p.rapidapi.com/webdata?url={url}&imgarr={imgarr}&generic={generic}\"\nquerystring = {\"generic\": \"\", \"imgarr\": \"\"}\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"webdata-crawler.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers, params=querystring)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 1,
            "schema": ""
        },
        {
            "name": "Get Images",
            "url": "https://webdata-crawler.p.rapidapi.com/images?url=https://github.com/",
            "description": "This service gets an array of images fetched from all the img tags retrieved by the provided url",
            "method": "GET",
            "required_parameters": [
                {
                    "name": "url",
                    "type": "STRING",
                    "description": "Url you want to crawl. No \"hashtags\" (#) on the url. Only urls that return html.",
                    "default": "https://github.com/"
                }
            ],
            "optional_parameters": [],
            "code": "import requests\n\nurl = \"https://webdata-crawler.p.rapidapi.com/images?url=https://github.com/\"\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"webdata-crawler.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers)\nprint(response.json())\n",
            "convert_code": "import requests\n\nurl = \"https://webdata-crawler.p.rapidapi.com/images?url={url}\"\n\nheaders = {\n            \"X-RapidAPI-Key\": \"SIGN-UP-FOR-KEY\",\n            \"X-RapidAPI-Host\": \"webdata-crawler.p.rapidapi.com\"\n        }\n\nresponse = requests.get(url, headers=headers)\nprint(response.json())\n",
            "test_endpoint": "",
            "statuscode": 1,
            "schema": ""
        }
    ]
}